{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Cleaning The Tweets ##########################\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "filename = 'train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: p.clean(re.sub('#', '',x))) #Tweet Cleaner\n",
    "df['tweet'] = df['tweet'].apply(lambda x: x.lower()) #Lower Casing\n",
    "df['tweet'] = df['tweet'].str.replace('[^\\w\\s]','') #Removing Punctuations\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))#STopwords Removal\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "df.to_csv('clean_'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import preprocessor as p\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks lyft credit cant use cause dont offer w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  father dysfunctional selfish drag kid dysfunct...\n",
       "1   2      0  thanks lyft credit cant use cause dont offer w...\n",
       "2   3      0                                     bihday majesty\n",
       "3   4      0                        model love u take u time ur\n",
       "4   5      0                      factsguide society motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "#normal = df[df['label']==0]\n",
    "#hate = df[df['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=2000,ngram_range=(1,2), min_df=5, max_df=0.5, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(df['tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31931, 2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6098 2786]\n",
      " [ 126  570]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      8884\n",
      "           1       0.17      0.82      0.28       696\n",
      "\n",
      "    accuracy                           0.70      9580\n",
      "   macro avg       0.57      0.75      0.54      9580\n",
      "weighted avg       0.92      0.70      0.77      9580\n",
      "\n",
      "Training Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81     20808\n",
      "           1       0.19      1.00      0.32      1543\n",
      "\n",
      "    accuracy                           0.70     22351\n",
      "   macro avg       0.59      0.84      0.56     22351\n",
      "weighted avg       0.94      0.70      0.78     22351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions = gnb.predict(X_test)\n",
    "#################### Gaussian NB Result #########################\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "#print(accuracy_score(y_test, predictions))\n",
    "print('Training Classification Report\\n',classification_report(y_train,gnb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8788   96]\n",
      " [ 353  343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      8884\n",
      "           1       0.78      0.49      0.60       696\n",
      "\n",
      "    accuracy                           0.95      9580\n",
      "   macro avg       0.87      0.74      0.79      9580\n",
      "weighted avg       0.95      0.95      0.95      9580\n",
      "\n",
      "Training Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20808\n",
      "           1       0.99      0.94      0.96      1543\n",
      "\n",
      "    accuracy                           0.99     22351\n",
      "   macro avg       0.99      0.97      0.98     22351\n",
      "weighted avg       0.99      0.99      0.99     22351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#text_classifier = RandomForestClassifier(n_estimators=30, random_state=0)  \n",
    "#text_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = text_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "#print(accuracy_score(y_test, predictions))\n",
    "print('Training Classification Report\\n',classification_report(y_train,text_classifier.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SMOTE<br></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import preprocessor as p\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "df = pd.read_csv('clean_train.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12772"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.sample(frac=0.4)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, Y, y_test = train_test_split(data['tweet'], data['label'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 2586)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=3000,ngram_range=(1,2), min_df=5, max_df=0.5, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3832, 2586)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfidfconverter.transform(X_test).toarray()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (16654, 2586)\n",
      "After OverSampling, the shape of train_y: (16654,) \n",
      "\n",
      "After OverSampling, counts of label '1': 8327\n",
      "After OverSampling, counts of label '0': 8327\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2,sampling_strategy=1)\n",
    "X,Y  = sm.fit_resample(X, Y)\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(Y.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(Y == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2919  637]\n",
      " [ 111  165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89      3556\n",
      "           1       0.21      0.60      0.31       276\n",
      "\n",
      "    accuracy                           0.80      3832\n",
      "   macro avg       0.58      0.71      0.60      3832\n",
      "weighted avg       0.91      0.80      0.84      3832\n",
      "\n",
      "Training Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92      8327\n",
      "           1       0.87      1.00      0.93      8327\n",
      "\n",
      "    accuracy                           0.92     16654\n",
      "   macro avg       0.93      0.92      0.92     16654\n",
      "weighted avg       0.93      0.92      0.92     16654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)\n",
    "predictions = gnb.predict(X_test)\n",
    "#################### Gaussian NB Result #########################\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "#print(accuracy_score(y_test, predictions))\n",
    "print('Training Classification Report\\n',classification_report(Y,gnb.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3401  155]\n",
      " [ 113  163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3556\n",
      "           1       0.51      0.59      0.55       276\n",
      "\n",
      "    accuracy                           0.93      3832\n",
      "   macro avg       0.74      0.77      0.76      3832\n",
      "weighted avg       0.94      0.93      0.93      3832\n",
      "\n",
      "Training Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8327\n",
      "           1       1.00      1.00      1.00      8327\n",
      "\n",
      "    accuracy                           1.00     16654\n",
      "   macro avg       1.00      1.00      1.00     16654\n",
      "weighted avg       1.00      1.00      1.00     16654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "text_classifier.fit(X, Y)\n",
    "\n",
    "predictions = text_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "#print(accuracy_score(y_test, predictions))\n",
    "print('Training Classification Report\\n',classification_report(Y,text_classifier.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                165568    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 178,561\n",
      "Trainable params: 178,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "Dense(input_dim = 2586, units = 64, activation = 'relu'),\n",
    "Dense(units = 128, activation = 'relu'),\n",
    "Dropout(0.5),\n",
    "Dense(units = 32, activation = 'relu'),\n",
    "Dense(units = 16, activation = 'relu'),\n",
    "Dense(units =1, activation = 'sigmoid'),])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1111/1111 [==============================] - 2s 1ms/step - loss: 0.3148 - accuracy: 0.8678 - val_loss: 0.3338 - val_accuracy: 0.9368\n",
      "Epoch 2/5\n",
      "1111/1111 [==============================] - 1s 1ms/step - loss: 0.0381 - accuracy: 0.9883 - val_loss: 0.3946 - val_accuracy: 0.9327\n",
      "Epoch 3/5\n",
      "1111/1111 [==============================] - 1s 1ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.4495 - val_accuracy: 0.9311\n",
      "Epoch 4/5\n",
      "1111/1111 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.4737 - val_accuracy: 0.9293\n",
      "Epoch 5/5\n",
      "1111/1111 [==============================] - 1s 1ms/step - loss: 0.0166 - accuracy: 0.9931 - val_loss: 0.4790 - val_accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16c746fe7f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X, Y, batch_size = 15, epochs = 5,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3478   78]\n",
      " [ 145  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3556\n",
      "           1       0.63      0.47      0.54       276\n",
      "\n",
      "    accuracy                           0.94      3832\n",
      "   macro avg       0.79      0.73      0.75      3832\n",
      "weighted avg       0.94      0.94      0.94      3832\n",
      "\n",
      "0.9418058455114823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
