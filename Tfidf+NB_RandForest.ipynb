{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Cleaning The Tweets ##########################\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "filename = 'train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: p.clean(re.sub('#', '',x))) #Tweet Cleaner\n",
    "df['tweet'] = df['tweet'].apply(lambda x: x.lower()) #Lower Casing\n",
    "df['tweet'] = df['tweet'].str.replace('[^\\w\\s]','') #Removing Punctuations\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))#STopwords Removal\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "df.to_csv('clean_'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import preprocessor as p\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  father dysfunctional selfish drag kid dysfunct...\n",
       "1   2      0  thanks lyft credit cant use cause dont offer w...\n",
       "2   3      0                                     bihday majesty\n",
       "3   4      0                        model love u take u time ur\n",
       "4   5      0                      factsguide society motivation"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>father dysfunctional selfish drag kid dysfunct...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>thanks lyft credit cant use cause dont offer w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>model love u take u time ur</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide society motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('clean_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "normal = df[df['label']==0]\n",
    "hate = df[df['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=10000,ngram_range=(1,2), min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(df['tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.75, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6526  880]\n [ 221  356]]\n              precision    recall  f1-score   support\n\n           0       0.97      0.88      0.92      7406\n           1       0.29      0.62      0.39       577\n\n    accuracy                           0.86      7983\n   macro avg       0.63      0.75      0.66      7983\nweighted avg       0.92      0.86      0.88      7983\n\n0.8620819240886884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions = gnb.predict(X_test)\n",
    "#################### Gaussian NB Result #########################\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[22191    96]\n [ 1003   659]]\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     22287\n           1       0.87      0.40      0.55      1662\n\n    accuracy                           0.95     23949\n   macro avg       0.91      0.70      0.76     23949\nweighted avg       0.95      0.95      0.95     23949\n\n0.9541108188233329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=30, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train)\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd060eb1d0f96393a1e0420bb6ca0f5435a81d9c3ff4319ce3c90a222065ab89d85",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}