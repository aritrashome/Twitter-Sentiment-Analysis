{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Cleaning The Tweets ##########################\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "filename = 'train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: p.clean(re.sub('#', '',x))) #Tweet Cleaner\n",
    "df['tweet'] = df['tweet'].apply(lambda x: x.lower()) #Lower Casing\n",
    "df['tweet'] = df['tweet'].str.replace('[^\\w\\s]','') #Removing Punctuations\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))#STopwords Removal\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "df.to_csv('clean_'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import preprocessor as p\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  father dysfunctional selfish drag kid dysfunct...\n",
       "1   2      0  thanks lyft credit cant use cause dont offer w...\n",
       "2   3      0                                     bihday majesty\n",
       "3   4      0                        model love u take u time ur\n",
       "4   5      0                      factsguide society motivation"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>father dysfunctional selfish drag kid dysfunct...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>thanks lyft credit cant use cause dont offer w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>model love u take u time ur</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide society motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('clean_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model', 'love', 'u', 'take', 'u', 'time', 'ur']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df['tweet'][3].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for tweet in df['tweet']:\n",
    "    sentences.append(tweet.split())\n",
    "    \n",
    "from gensim.models import Word2Vec\n",
    "w2vev = Word2Vec(sentences, min_count=5,window=3,size =100)\n",
    "w2vev.save('w2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2vec = Word2Vec.load('w2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/31931 [00:00<?, ?it/s]ipykernel_launcher:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "100%|██████████| 31931/31931 [00:01<00:00, 22627.13it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for tweet in tqdm(df['tweet']):\n",
    "    mean = np.zeros(100)\n",
    "    cnt = 0.0\n",
    "    for token in tweet.split():\n",
    "        if token in w2vec.wv.vocab:\n",
    "            mean += w2vec[token]\n",
    "            cnt += 1.0\n",
    "    if cnt!=0: mean /= cnt\n",
    "    X.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31931"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4258 4626]\n",
      " [  84  612]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.64      8884\n",
      "           1       0.12      0.88      0.21       696\n",
      "\n",
      "    accuracy                           0.51      9580\n",
      "   macro avg       0.55      0.68      0.43      9580\n",
      "weighted avg       0.92      0.51      0.61      9580\n",
      "\n",
      "0.5083507306889353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions = gnb.predict(X_test)\n",
    "#################### Gaussian NB Result #########################\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[8858   26]\n [ 492  204]]\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      8884\n           1       0.89      0.29      0.44       696\n\n    accuracy                           0.95      9580\n   macro avg       0.92      0.65      0.71      9580\nweighted avg       0.94      0.95      0.93      9580\n\n0.945929018789144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=30, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train)\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd060eb1d0f96393a1e0420bb6ca0f5435a81d9c3ff4319ce3c90a222065ab89d85",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}